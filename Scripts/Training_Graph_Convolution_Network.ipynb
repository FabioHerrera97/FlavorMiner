{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# TRAINING, OPTIMIZING, AND SELECTING THE DEEP LEARNING ALGORITHMS FOR FLAVOR PREDICTION WITH MOLECULAR GRAPHS\n",
        "\n",
        "IMPORTANT NOTE! Activate the GPUs of Google Colab to speed up the running of This code. Go to Edit>Notebook settings>T4 GPU\n",
        "\n",
        "This script comprises the process for training, hyperprameter optimization and testing the Machine Learning algorithms for flavor prediction. The data for both training, validation, and testing is splitted using a partition training-testing 70:10:20.\n",
        "\n",
        "The selected algorithm was a Convolutional Graph Neural Network (GraphConvModel), from the Python Library DeepChem.\n",
        "\n",
        "Check out the DeepChem documentation of DeepChem for further information.\n",
        "\n",
        "[https://deepchem.io/](https://)\n",
        "\n"
      ],
      "metadata": {
        "id": "VHP4gClxRTom"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "DeepChem is not a default library in Google Colab. Therefore, it must be installed. Also, Deepchem requires RDKit to be installed in order to work. Similarly, hyperopt was the selected library for optimizing the hyperparameters of the Neural Network, and it must also be installed. This library was selected because there is plenty of documentation to use it with DeepChem, facilitating the configuration and running."
      ],
      "metadata": {
        "id": "LhaVRldQVxgp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fw6xAIUCFKRo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9888ff60-91cf-4e67-ea25-801d0434ad00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rdkit-pypi\n",
            "  Downloading rdkit_pypi-2022.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.4/29.4 MB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting deepchem\n",
            "  Downloading deepchem-2.7.1-py3-none-any.whl (693 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m693.2/693.2 kB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: hyperopt in /usr/local/lib/python3.10/dist-packages (0.2.7)\n",
            "Collecting pytorch_lightning\n",
            "  Downloading pytorch_lightning-2.0.7-py3-none-any.whl (724 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m725.0/725.0 kB\u001b[0m \u001b[31m73.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lightning\n",
            "  Downloading lightning-2.0.7-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m91.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rdkit-pypi) (1.23.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit-pypi) (9.4.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from deepchem) (1.3.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from deepchem) (1.5.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from deepchem) (1.2.2)\n",
            "Collecting scipy<1.9 (from deepchem)\n",
            "  Downloading scipy-1.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rdkit (from deepchem)\n",
            "  Downloading rdkit-2023.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.7/29.7 MB\u001b[0m \u001b[31m69.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from hyperopt) (1.16.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from hyperopt) (3.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from hyperopt) (0.18.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from hyperopt) (4.66.1)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from hyperopt) (2.2.1)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (from hyperopt) (0.10.9.7)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (2.0.1+cu118)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (6.0.1)\n",
            "Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (2023.6.0)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch_lightning)\n",
            "  Downloading torchmetrics-1.0.3-py3-none-any.whl (731 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.6/731.6 kB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (23.1)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (4.7.1)\n",
            "Collecting lightning-utilities>=0.7.0 (from pytorch_lightning)\n",
            "  Downloading lightning_utilities-0.9.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: Jinja2<5.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (3.1.2)\n",
            "Collecting arrow<3.0,>=1.2.0 (from lightning)\n",
            "  Downloading arrow-1.2.3-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting backoff<4.0,>=2.2.1 (from lightning)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: beautifulsoup4<6.0,>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (4.11.2)\n",
            "Requirement already satisfied: click<10.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (8.1.6)\n",
            "Collecting croniter<1.5.0,>=1.3.0 (from lightning)\n",
            "  Downloading croniter-1.4.1-py2.py3-none-any.whl (19 kB)\n",
            "Collecting dateutils<2.0 (from lightning)\n",
            "  Downloading dateutils-0.6.12-py2.py3-none-any.whl (5.7 kB)\n",
            "Collecting deepdiff<8.0,>=5.7.0 (from lightning)\n",
            "  Downloading deepdiff-6.3.1-py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.7/70.7 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi<2.0,>=0.92.0 (from lightning)\n",
            "  Downloading fastapi-0.101.1-py3-none-any.whl (65 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting inquirer<5.0,>=2.10.0 (from lightning)\n",
            "  Downloading inquirer-3.1.3-py3-none-any.whl (18 kB)\n",
            "Collecting lightning-cloud>=0.5.37 (from lightning)\n",
            "  Downloading lightning_cloud-0.5.37-py3-none-any.whl (596 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m596.7/596.7 kB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil<7.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (5.9.5)\n",
            "Requirement already satisfied: pydantic<2.2.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from lightning) (2.1.1)\n",
            "Collecting python-multipart<2.0,>=0.0.5 (from lightning)\n",
            "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<4.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (2.31.0)\n",
            "Requirement already satisfied: rich<15.0,>=12.3.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (13.5.2)\n",
            "Collecting starlette (from lightning)\n",
            "  Downloading starlette-0.31.0-py3-none-any.whl (69 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.8/69.8 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting starsessions<2.0,>=1.2.1 (from lightning)\n",
            "  Downloading starsessions-1.3.0-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: traitlets<7.0,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (5.7.1)\n",
            "Requirement already satisfied: urllib3<4.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (2.0.4)\n",
            "Collecting uvicorn<2.0 (from lightning)\n",
            "  Downloading uvicorn-0.23.2-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: websocket-client<3.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (1.6.1)\n",
            "Collecting websockets<13.0 (from lightning)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from arrow<3.0,>=1.2.0->lightning) (2.8.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<6.0,>=4.8.0->lightning) (2.4.1)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from dateutils<2.0->lightning) (2023.3)\n",
            "Collecting ordered-set<4.2.0,>=4.0.2 (from deepdiff<8.0,>=5.7.0->lightning)\n",
            "  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
            "Collecting starlette (from lightning)\n",
            "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>2021.06.0->pytorch_lightning) (3.8.5)\n",
            "Collecting blessed>=1.19.0 (from inquirer<5.0,>=2.10.0->lightning)\n",
            "  Downloading blessed-1.20.0-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-editor>=1.0.4 (from inquirer<5.0,>=2.10.0->lightning)\n",
            "  Downloading python_editor-1.0.4-py3-none-any.whl (4.9 kB)\n",
            "Collecting readchar>=3.0.6 (from inquirer<5.0,>=2.10.0->lightning)\n",
            "  Downloading readchar-4.0.5-py3-none-any.whl (8.5 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2<5.0->lightning) (2.1.3)\n",
            "Requirement already satisfied: pyjwt in /usr/lib/python3/dist-packages (from lightning-cloud>=0.5.37->lightning) (2.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2.2.0,>=1.7.4->lightning) (0.5.0)\n",
            "Requirement already satisfied: pydantic-core==2.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2.2.0,>=1.7.4->lightning) (2.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<4.0->lightning) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<4.0->lightning) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<4.0->lightning) (2023.7.22)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<15.0,>=12.3.0->lightning) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<15.0,>=12.3.0->lightning) (2.16.1)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette->lightning) (3.7.1)\n",
            "Requirement already satisfied: itsdangerous<3.0.0,>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from starsessions<2.0,>=1.2.1->lightning) (2.1.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch_lightning) (3.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch_lightning) (1.12)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch_lightning) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.11.0->pytorch_lightning) (3.27.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.11.0->pytorch_lightning) (16.0.6)\n",
            "Collecting h11>=0.8 (from uvicorn<2.0->lightning)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->deepchem) (3.2.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.3.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette->lightning) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette->lightning) (1.1.2)\n",
            "Requirement already satisfied: wcwidth>=0.1.4 in /usr/local/lib/python3.10/dist-packages (from blessed>=1.19.0->inquirer<5.0,>=2.10.0->lightning) (0.2.6)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<15.0,>=12.3.0->lightning) (0.1.2)\n",
            "Requirement already satisfied: setuptools>=41.0 in /usr/local/lib/python3.10/dist-packages (from readchar>=3.0.6->inquirer<5.0,>=2.10.0->lightning) (67.7.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->pytorch_lightning) (1.3.0)\n",
            "Installing collected packages: python-editor, websockets, scipy, readchar, rdkit-pypi, rdkit, python-multipart, ordered-set, lightning-utilities, h11, blessed, backoff, uvicorn, starlette, inquirer, deepdiff, dateutils, croniter, arrow, starsessions, fastapi, deepchem, lightning-cloud, torchmetrics, pytorch_lightning, lightning\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.10.1\n",
            "    Uninstalling scipy-1.10.1:\n",
            "      Successfully uninstalled scipy-1.10.1\n",
            "Successfully installed arrow-1.2.3 backoff-2.2.1 blessed-1.20.0 croniter-1.4.1 dateutils-0.6.12 deepchem-2.7.1 deepdiff-6.3.1 fastapi-0.101.1 h11-0.14.0 inquirer-3.1.3 lightning-2.0.7 lightning-cloud-0.5.37 lightning-utilities-0.9.0 ordered-set-4.1.0 python-editor-1.0.4 python-multipart-0.0.6 pytorch_lightning-2.0.7 rdkit-2023.3.2 rdkit-pypi-2022.9.5 readchar-4.0.5 scipy-1.8.1 starlette-0.27.0 starsessions-1.3.0 torchmetrics-1.0.3 uvicorn-0.23.2 websockets-11.0.3\n"
          ]
        }
      ],
      "source": [
        "! pip install rdkit-pypi deepchem hyperopt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import deepchem as dc\n",
        "from deepchem.models import GCNModel\n",
        "from hyperopt import hp, fmin, tpe, Trials\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import tempfile"
      ],
      "metadata": {
        "id": "csfYFswEG6gu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8b86006-fc85-415c-d3c0-ec6a0dba6dda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:deepchem.models.torch_models:Skipped loading modules with pytorch-geometric dependency, missing a dependency. No module named 'torch_geometric'\n",
            "WARNING:deepchem.models:Skipped loading modules with pytorch-geometric dependency, missing a dependency. cannot import name 'DMPNN' from 'deepchem.models.torch_models' (/usr/local/lib/python3.10/dist-packages/deepchem/models/torch_models/__init__.py)\n",
            "WARNING:deepchem.models:Skipped loading some Jax models, missing a dependency. No module named 'haiku'\n",
            "DGL backend not selected or invalid.  Assuming PyTorch for now.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Training the Convolutional Graph Neural Network with the original data\n",
        "\n"
      ],
      "metadata": {
        "id": "A-zR7cX8WRWi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This fuction takes as input a  trained model, a dataset, a label and an empty dictionary and add to the dictionary the metrics for the respective label. This function needs to be configure before the training to obtain the performance also during the training."
      ],
      "metadata": {
        "id": "1BTGYLdJT4A_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def performance_metrics(model, dataset, label, metrics_dictionary):\n",
        "\n",
        "  ''' Use the train model to do the prediction'''\n",
        "  predictions = model.predict(dataset)\n",
        "  true_labels = dataset.y\n",
        "\n",
        "  ''' Calculate the recall'''\n",
        "  recall = model.evaluate(dataset, [dc.metrics.Metric(dc.metrics.recall_score, mode='classification')])\n",
        "\n",
        "  ''' Calculate the specificity'''\n",
        "  threshold = 0.5\n",
        "  binary_predictions = (predictions[:, 1] >= threshold).astype(int)\n",
        "  tn, fp, fn, tp = confusion_matrix(dataset.y, binary_predictions).ravel()\n",
        "  specificity = tn / (tn + fp)\n",
        "\n",
        "  ''' Calculate the roc score'''\n",
        "  roc_auc = model.evaluate(dataset, [dc.metrics.Metric(dc.metrics.roc_auc_score, mode='classification')])\n",
        "\n",
        "  ''' Store the metrics in the metrics dictionary'''\n",
        "  metrics_dictionary[('CGNN', label)] = {'Recall': recall['recall_score'], 'Specificity': specificity,\n",
        "                                                 'ROC Score': roc_auc['roc_auc_score']}"
      ],
      "metadata": {
        "id": "HwUF-fBHLRAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The selceted model was a preconfigured Graph Convolutional Neural Network (GCNModel) from DeepChem. This model was selected because is the recommended for the featurizer used to produce the molecular graphs (MolGraphConvFeaturizer). The hyperparameter optimization during during the training was performed with the library hyperopt.  \n",
        "\n",
        "The partion used in the data to train the Neural Networks was 70:10:20 train-validation-test. These datasets were previously splitted using the script \"FeaturizationSplitingResampling\" and stored as joblib files as this is one of the best ways to store graph data.\n",
        "\n",
        "A fuction taking as input the tags for the different datasets (Train, Validation, and Test) and perform the training and test both with the validation set during the training and test."
      ],
      "metadata": {
        "id": "pWXZJZ1cDJCs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def training_GCNModel(tag_train, tag_val, tag_test, tag_train_and_val):\n",
        "\n",
        "  labels = ['Bitter', 'Floral', 'Fruity', 'Off_flavor', 'Nutty', 'Sour', 'Sweet']\n",
        "  models_CGNN = []\n",
        "\n",
        "  evaluation_metrics_test = {}\n",
        "  evaluation_metrics_valid = {}\n",
        "\n",
        "  for label in labels:\n",
        "\n",
        "    print(f'Training the Neural Network for {label}')\n",
        "\n",
        "    # Create the train, validation, and test datasets\n",
        "\n",
        "    train_data = dc.utils.load_from_disk(f'{tag_train}_{label}.joblib')\n",
        "    valid_dataset = dc.utils.load_from_disk(f'{tag_val}_{label}.joblib')\n",
        "    test_data = dc.utils.load_from_disk(f'{tag_test}_{label}.joblib')\n",
        "    train_and_valid_data = dc.utils.load_from_disk(f'{tag_train_and_val}_{label}.joblib')\n",
        "\n",
        "    search_space = { 'layer_sizes': hp.choice('layer_sizes',[[500], [1000], [2000]]),\n",
        "                    'learning_rate': hp.uniform('learning_rate', high=0.001, low=0.0001)}\n",
        "\n",
        "    metric = dc.metrics.Metric(dc.metrics.roc_auc_score)\n",
        "\n",
        "    def fm(args):\n",
        "\n",
        "      save_dir = tempfile.mkdtemp()\n",
        "\n",
        "      model = GCNModel(mode='classification', n_tasks=1, dropout=0.4)\n",
        "\n",
        "      #validation callback that saves the best checkpoint, i.e the one with the maximum score.\n",
        "\n",
        "      validation=dc.models.ValidationCallback(valid_dataset, 1000,[metric],save_dir=save_dir)\n",
        "      model.fit(train_data, nb_epoch=25,callbacks=validation)\n",
        "\n",
        "      #restoring the best checkpoint and passing the negative of its validation score to be minimized.\n",
        "\n",
        "      model.restore(model_dir=model.model_dir)\n",
        "      valid_score = model.evaluate(valid_dataset, [metric])\n",
        "\n",
        "      performance_metrics(model, valid_dataset, label, evaluation_metrics_valid)\n",
        "\n",
        "      return -1*valid_score['roc_auc_score']\n",
        "\n",
        "    trials=Trials()\n",
        "\n",
        "    best_hyperparameters = fmin(fm, space= search_space, algo=tpe.suggest, max_evals=5, trials = trials)\n",
        "\n",
        "    best_model = GCNModel(mode='classification', n_tasks=1, dropout=0.4, **best_hyperparameters)\n",
        "\n",
        "    print('Training the best estimator with the best hyperparameters\\n')\n",
        "\n",
        "    best_model.fit(train_and_valid_data, nb_epoch=25)\n",
        "\n",
        "    models_CGNN.append(('CGNN', label, best_model))\n",
        "\n",
        "    # Test the models\n",
        "\n",
        "    performance_metrics(best_model, test_data, label, evaluation_metrics_test)\n",
        "\n",
        "  return models_CGNN, evaluation_metrics_test, evaluation_metrics_valid"
      ],
      "metadata": {
        "id": "hknBUV5C-FUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_original, metrics_test_original, metrics_valid_original = training_GCNModel('train_data', 'valid_dataset',\n",
        "                                                                                  'test_data', 'train_and_valid_data')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvmvcP87UDPw",
        "outputId": "d8bc791a-6934-44e7-d08d-e772eab874fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training the Neural Network for Bitter\n",
            "  0%|          | 0/5 [00:00<?, ?trial/s, best loss=?]Step 1000 validation: roc_auc_score=0.701496\n",
            "Step 2000 validation: roc_auc_score=0.714194\n",
            " 20%|██        | 1/5 [03:53<15:32, 233.07s/trial, best loss: -0.7133275548951625]Step 1000 validation: roc_auc_score=0.645409\n",
            "Step 2000 validation: roc_auc_score=0.719069\n",
            " 40%|████      | 2/5 [07:49<11:44, 234.81s/trial, best loss: -0.7391286159859711]Step 1000 validation: roc_auc_score=0.721794\n",
            "Step 2000 validation: roc_auc_score=0.682861\n",
            " 60%|██████    | 3/5 [11:39<07:45, 232.62s/trial, best loss: -0.7391286159859711]Step 1000 validation: roc_auc_score=0.759539\n",
            "Step 2000 validation: roc_auc_score=0.7567\n",
            " 80%|████████  | 4/5 [15:26<03:50, 230.65s/trial, best loss: -0.7391286159859711]Step 1000 validation: roc_auc_score=0.708648\n",
            "Step 2000 validation: roc_auc_score=0.666173\n",
            "100%|██████████| 5/5 [19:13<00:00, 230.67s/trial, best loss: -0.7391286159859711]\n",
            "Training the best estimator with the best hyperparameters\n",
            "Training the Neural Network for Floral\n",
            "  0%|          | 0/5 [00:00<?, ?trial/s, best loss=?]Step 1000 validation: roc_auc_score=0.656225\n",
            "Step 2000 validation: roc_auc_score=0.668667\n",
            " 20%|██        | 1/5 [03:49<15:17, 229.37s/trial, best loss: -0.6422576953549106]Step 1000 validation: roc_auc_score=0.759999\n",
            "Step 2000 validation: roc_auc_score=0.613794\n",
            " 40%|████      | 2/5 [07:38<11:27, 229.09s/trial, best loss: -0.6422576953549106]Step 1000 validation: roc_auc_score=0.760927\n",
            "Step 2000 validation: roc_auc_score=0.651266\n",
            " 60%|██████    | 3/5 [11:27<07:38, 229.29s/trial, best loss: -0.6688429824818803]Step 1000 validation: roc_auc_score=0.5038\n",
            "Step 2000 validation: roc_auc_score=0.560609\n",
            " 80%|████████  | 4/5 [15:22<03:51, 231.55s/trial, best loss: -0.6688429824818803]Step 1000 validation: roc_auc_score=0.612195\n",
            "Step 2000 validation: roc_auc_score=0.686699\n",
            "100%|██████████| 5/5 [19:17<00:00, 231.44s/trial, best loss: -0.680507057131958]\n",
            "Training the best estimator with the best hyperparameters\n",
            "Training the Neural Network for Fruity\n",
            "  0%|          | 0/5 [00:00<?, ?trial/s, best loss=?]Step 1000 validation: roc_auc_score=0.827002\n",
            "Step 2000 validation: roc_auc_score=0.749639\n",
            " 20%|██        | 1/5 [03:56<15:44, 236.06s/trial, best loss: -0.7892980417018878]Step 1000 validation: roc_auc_score=0.790117\n",
            "Step 2000 validation: roc_auc_score=0.776891\n",
            " 40%|████      | 2/5 [07:57<11:57, 239.29s/trial, best loss: -0.7892980417018878]Step 1000 validation: roc_auc_score=0.838916\n",
            "Step 2000 validation: roc_auc_score=0.763093\n",
            " 60%|██████    | 3/5 [11:55<07:57, 238.56s/trial, best loss: -0.8100609326570866]Step 1000 validation: roc_auc_score=0.827645\n",
            "Step 2000 validation: roc_auc_score=0.681125\n",
            " 80%|████████  | 4/5 [15:52<03:58, 238.22s/trial, best loss: -0.8100609326570866]Step 1000 validation: roc_auc_score=0.787828\n",
            "Step 2000 validation: roc_auc_score=0.764846\n",
            "100%|██████████| 5/5 [19:51<00:00, 238.39s/trial, best loss: -0.8100609326570866]\n",
            "Training the best estimator with the best hyperparameters\n",
            "Training the Neural Network for Off_flavor\n",
            "  0%|          | 0/5 [00:00<?, ?trial/s, best loss=?]Step 1000 validation: roc_auc_score=0.830883\n",
            "Step 2000 validation: roc_auc_score=0.642773\n",
            " 20%|██        | 1/5 [03:56<15:46, 236.70s/trial, best loss: -0.6458135177979536]Step 1000 validation: roc_auc_score=0.793818\n",
            "Step 2000 validation: roc_auc_score=0.465316\n",
            " 40%|████      | 2/5 [07:54<11:52, 237.58s/trial, best loss: -0.6458135177979536]Step 1000 validation: roc_auc_score=0.759187\n",
            "Step 2000 validation: roc_auc_score=0.611543\n",
            " 60%|██████    | 3/5 [11:54<07:56, 238.47s/trial, best loss: -0.6496901570831533]Step 1000 validation: roc_auc_score=0.617034\n",
            "Step 2000 validation: roc_auc_score=0.591382\n",
            " 80%|████████  | 4/5 [15:49<03:57, 237.21s/trial, best loss: -0.6496901570831533]Step 1000 validation: roc_auc_score=0.738219\n",
            "Step 2000 validation: roc_auc_score=0.560657\n",
            "100%|██████████| 5/5 [19:45<00:00, 237.07s/trial, best loss: -0.6496901570831533]\n",
            "Training the best estimator with the best hyperparameters\n",
            "Training the Neural Network for Nutty\n",
            "  0%|          | 0/5 [00:00<?, ?trial/s, best loss=?]Step 1000 validation: roc_auc_score=0.774681\n",
            "Step 2000 validation: roc_auc_score=0.694099\n",
            " 20%|██        | 1/5 [03:54<15:39, 234.75s/trial, best loss: -0.6366459627329193]Step 1000 validation: roc_auc_score=0.784734\n",
            "Step 2000 validation: roc_auc_score=0.723895\n",
            " 40%|████      | 2/5 [07:52<11:49, 236.60s/trial, best loss: -0.6896316879154408]Step 1000 validation: roc_auc_score=0.79247\n",
            "Step 2000 validation: roc_auc_score=0.503133\n",
            " 60%|██████    | 3/5 [11:46<07:50, 235.17s/trial, best loss: -0.6896316879154408]Step 1000 validation: roc_auc_score=0.715212\n",
            "Step 2000 validation: roc_auc_score=0.635066\n",
            " 80%|████████  | 4/5 [15:40<03:55, 235.05s/trial, best loss: -0.6954342377683339]Step 1000 validation: roc_auc_score=0.69083\n",
            "Step 2000 validation: roc_auc_score=0.716302\n",
            "100%|██████████| 5/5 [19:36<00:00, 235.31s/trial, best loss: -0.6954342377683339]\n",
            "Training the best estimator with the best hyperparameters\n",
            "Training the Neural Network for Sour\n",
            "  0%|          | 0/5 [00:00<?, ?trial/s, best loss=?]Step 1000 validation: roc_auc_score=0.668086\n",
            "Step 2000 validation: roc_auc_score=0.682588\n",
            " 20%|██        | 1/5 [03:56<15:45, 236.45s/trial, best loss: -0.655256064690027]Step 1000 validation: roc_auc_score=0.734987\n",
            "Step 2000 validation: roc_auc_score=0.618329\n",
            " 40%|████      | 2/5 [07:52<11:48, 236.29s/trial, best loss: -0.6725067385444744]Step 1000 validation: roc_auc_score=0.672453\n",
            "Step 2000 validation: roc_auc_score=0.669003\n",
            " 60%|██████    | 3/5 [11:51<07:54, 237.34s/trial, best loss: -0.6725067385444744]Step 1000 validation: roc_auc_score=0.541024\n",
            "Step 2000 validation: roc_auc_score=0.580485\n",
            " 80%|████████  | 4/5 [15:48<03:57, 237.49s/trial, best loss: -0.6725067385444744]Step 1000 validation: roc_auc_score=0.705714\n",
            "Step 2000 validation: roc_auc_score=0.581941\n",
            "100%|██████████| 5/5 [19:43<00:00, 236.66s/trial, best loss: -0.6725067385444744]\n",
            "Training the best estimator with the best hyperparameters\n",
            "Training the Neural Network for Sweet\n",
            "  0%|          | 0/5 [00:00<?, ?trial/s, best loss=?]Step 1000 validation: roc_auc_score=0.75086\n",
            "Step 2000 validation: roc_auc_score=0.792468\n",
            " 20%|██        | 1/5 [04:00<16:03, 240.86s/trial, best loss: -0.8261908905574065]Step 1000 validation: roc_auc_score=0.749037\n",
            "Step 2000 validation: roc_auc_score=0.81819\n",
            " 40%|████      | 2/5 [07:59<11:59, 239.72s/trial, best loss: -0.8261908905574065]Step 1000 validation: roc_auc_score=0.777875\n",
            "Step 2000 validation: roc_auc_score=0.792814\n",
            " 60%|██████    | 3/5 [11:54<07:55, 237.56s/trial, best loss: -0.8261908905574065]Step 1000 validation: roc_auc_score=0.773333\n",
            "Step 2000 validation: roc_auc_score=0.781076\n",
            " 80%|████████  | 4/5 [15:46<03:55, 235.23s/trial, best loss: -0.8261908905574065]Step 1000 validation: roc_auc_score=0.741178\n",
            "Step 2000 validation: roc_auc_score=0.753305\n",
            "100%|██████████| 5/5 [19:38<00:00, 235.63s/trial, best loss: -0.8261908905574065]\n",
            "Training the best estimator with the best hyperparameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The metrics both during training and testing were converted to a DataFrame and finally stored in excel files."
      ],
      "metadata": {
        "id": "brzncteGLOCY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metrics_test_df = pd.DataFrame.from_dict(metrics_test_original, orient='index')\n",
        "\n",
        "print(metrics_test_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQN9MBqtgUpb",
        "outputId": "88ef6e95-85d9-4744-c93b-6850737dd3cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   Recall  Specificity  ROC Score\n",
            "CGNN Bitter      0.129676     0.994291   0.594583\n",
            "     Floral      0.003540     0.991008   0.700110\n",
            "     Fruity      0.004739     0.980543   0.707994\n",
            "     Off_flavor  0.936765     0.216216   0.670555\n",
            "     Nutty       0.000000     0.999580   0.621557\n",
            "     Sour        0.000000     0.991535   0.575059\n",
            "     Sweet       0.350000     0.948037   0.759007\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metrics_val_df = pd.DataFrame.from_dict(metrics_valid_original, orient='index')\n",
        "\n",
        "print(metrics_val_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdKjxRCUFh-u",
        "outputId": "7417088a-f94d-4d09-be24-b7da63d4c464"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   Recall  Specificity  ROC Score\n",
            "CGNN Bitter      0.375375     0.915305   0.735133\n",
            "     Floral      0.000000     0.951788   0.680507\n",
            "     Fruity      0.021978     0.920673   0.676449\n",
            "     Off_flavor  0.037037     0.860700   0.607220\n",
            "     Nutty       0.035714     0.969489   0.678599\n",
            "     Sour        0.000000     1.000000   0.547278\n",
            "     Sweet       0.503297     0.866516   0.805504\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metrics_val_df.to_excel('Validation_metrics_original.xlsx')\n",
        "metrics_test_df.to_excel('Test_metrics_original.xlsx')"
      ],
      "metadata": {
        "id": "3vdHvIl2PTjV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Training the Convolutional Graph Neural Network with the data balanced with the transformer\n",
        "\n",
        "The process above described was repeated with the balanced molecular graphs"
      ],
      "metadata": {
        "id": "GcAw9eANLTd_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_balanced, metrics_test_balanced, metrics_valid_balanced = training_GCNModel('balanced_train_data', 'balanced_valid_dataset',\n",
        "                                                                                  'balanced_test_data', 'balanced_train_and_valid_data')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5US2AMveKTi",
        "outputId": "550bf528-2f4b-4b9b-ee87-425f372941ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training the Neural Network for Bitter\n",
            "  0%|          | 0/5 [00:00<?, ?trial/s, best loss=?]Step 1000 validation: roc_auc_score=0.620289\n",
            "Step 2000 validation: roc_auc_score=0.767146\n",
            " 20%|██        | 1/5 [02:27<09:50, 147.67s/trial, best loss: -0.760091071755262]Step 1000 validation: roc_auc_score=0.697691\n",
            "Step 2000 validation: roc_auc_score=0.719533\n",
            " 40%|████      | 2/5 [04:52<07:18, 146.25s/trial, best loss: -0.760091071755262]Step 1000 validation: roc_auc_score=0.667387\n",
            "Step 2000 validation: roc_auc_score=0.71601\n",
            " 60%|██████    | 3/5 [07:18<04:51, 145.97s/trial, best loss: -0.760091071755262]Step 1000 validation: roc_auc_score=0.752097\n",
            "Step 2000 validation: roc_auc_score=0.715556\n",
            " 80%|████████  | 4/5 [09:43<02:25, 145.54s/trial, best loss: -0.761765480190443]Step 1000 validation: roc_auc_score=0.76262\n",
            "Step 2000 validation: roc_auc_score=0.757026\n",
            "100%|██████████| 5/5 [12:11<00:00, 146.38s/trial, best loss: -0.761765480190443]\n",
            "Training the best estimator with the best hyperparameters\n",
            "\n",
            "Training the Neural Network for Floral\n",
            "  0%|          | 0/5 [00:00<?, ?trial/s, best loss=?]Step 1000 validation: roc_auc_score=0.752766\n",
            "Step 2000 validation: roc_auc_score=0.706682\n",
            " 20%|██        | 1/5 [02:31<10:06, 151.66s/trial, best loss: -0.5607265471404677]Step 1000 validation: roc_auc_score=0.716512\n",
            "Step 2000 validation: roc_auc_score=0.660099\n",
            " 40%|████      | 2/5 [05:04<07:37, 152.58s/trial, best loss: -0.6286276005751341]Step 1000 validation: roc_auc_score=0.533217\n",
            "Step 2000 validation: roc_auc_score=0.677558\n",
            " 60%|██████    | 3/5 [07:38<05:06, 153.21s/trial, best loss: -0.6422723671469234]Step 1000 validation: roc_auc_score=0.744641\n",
            "Step 2000 validation: roc_auc_score=0.653995\n",
            " 80%|████████  | 4/5 [10:12<02:33, 153.23s/trial, best loss: -0.6422723671469234]Step 1000 validation: roc_auc_score=0.812759\n",
            "Step 2000 validation: roc_auc_score=0.627498\n",
            "100%|██████████| 5/5 [12:45<00:00, 153.04s/trial, best loss: -0.6422723671469234]\n",
            "Training the best estimator with the best hyperparameters\n",
            "\n",
            "Training the Neural Network for Fruity\n",
            "  0%|          | 0/5 [00:00<?, ?trial/s, best loss=?]Step 1000 validation: roc_auc_score=0.801185\n",
            "Step 2000 validation: roc_auc_score=0.771245\n",
            " 20%|██        | 1/5 [02:32<10:11, 152.97s/trial, best loss: -0.7379015215553677]Step 1000 validation: roc_auc_score=0.758488\n",
            "Step 2000 validation: roc_auc_score=0.701395\n",
            " 40%|████      | 2/5 [05:08<07:42, 154.20s/trial, best loss: -0.7764423076923077]Step 1000 validation: roc_auc_score=0.750211\n",
            "Step 2000 validation: roc_auc_score=0.765083\n",
            " 60%|██████    | 3/5 [07:42<05:08, 154.30s/trial, best loss: -0.7764423076923077]Step 1000 validation: roc_auc_score=0.823773\n",
            "Step 2000 validation: roc_auc_score=0.737347\n",
            " 80%|████████  | 4/5 [10:17<02:34, 154.70s/trial, best loss: -0.7764423076923077]Step 1000 validation: roc_auc_score=0.834359\n",
            "Step 2000 validation: roc_auc_score=0.78007\n",
            "100%|██████████| 5/5 [12:53<00:00, 154.76s/trial, best loss: -0.7764423076923077]\n",
            "Training the best estimator with the best hyperparameters\n",
            "\n",
            "Training the Neural Network for Off_flavor\n",
            "  0%|          | 0/5 [00:00<?, ?trial/s, best loss=?]Step 1000 validation: roc_auc_score=0.685812\n",
            "Step 2000 validation: roc_auc_score=0.540611\n",
            " 20%|██        | 1/5 [02:36<10:26, 156.64s/trial, best loss: -0.6006629197290676]Step 1000 validation: roc_auc_score=0.699193\n",
            "Step 2000 validation: roc_auc_score=0.629947\n",
            " 40%|████      | 2/5 [05:11<07:46, 155.64s/trial, best loss: -0.6006629197290676]Step 1000 validation: roc_auc_score=0.599409\n",
            "Step 2000 validation: roc_auc_score=0.542773\n",
            " 60%|██████    | 3/5 [07:46<05:10, 155.38s/trial, best loss: -0.6090935293269923]Step 1000 validation: roc_auc_score=0.748955\n",
            "Step 2000 validation: roc_auc_score=0.580775\n",
            " 80%|████████  | 4/5 [10:21<02:35, 155.26s/trial, best loss: -0.6568813950136907]Step 1000 validation: roc_auc_score=0.776005\n",
            "Step 2000 validation: roc_auc_score=0.674751\n",
            "100%|██████████| 5/5 [12:56<00:00, 155.21s/trial, best loss: -0.6568813950136907]\n",
            "Training the best estimator with the best hyperparameters\n",
            "\n",
            "Training the Neural Network for Nutty\n",
            "  0%|          | 0/5 [00:00<?, ?trial/s, best loss=?]Step 1000 validation: roc_auc_score=0.786423\n",
            "Step 2000 validation: roc_auc_score=0.743871\n",
            " 20%|██        | 1/5 [02:34<10:16, 154.11s/trial, best loss: -0.7761250953470633]Step 1000 validation: roc_auc_score=0.838353\n",
            "Step 2000 validation: roc_auc_score=0.738722\n",
            " 40%|████      | 2/5 [05:13<07:51, 157.25s/trial, best loss: -0.7761250953470633]Step 1000 validation: roc_auc_score=0.724127\n",
            "Step 2000 validation: roc_auc_score=0.653209\n",
            " 60%|██████    | 3/5 [07:49<05:13, 156.62s/trial, best loss: -0.7761250953470633]Step 1000 validation: roc_auc_score=0.742774\n",
            "Step 2000 validation: roc_auc_score=0.598344\n",
            " 80%|████████  | 4/5 [10:25<02:36, 156.58s/trial, best loss: -0.7761250953470633]Step 1000 validation: roc_auc_score=0.808162\n",
            "Step 2000 validation: roc_auc_score=0.689387\n",
            "100%|██████████| 5/5 [13:01<00:00, 156.25s/trial, best loss: -0.7761250953470633]\n",
            "Training the best estimator with the best hyperparameters\n",
            "\n",
            "Training the Neural Network for Sour\n",
            "  0%|          | 0/5 [00:00<?, ?trial/s, best loss=?]Step 1000 validation: roc_auc_score=0.715957\n",
            "Step 2000 validation: roc_auc_score=0.665283\n",
            " 20%|██        | 1/5 [02:33<10:15, 153.83s/trial, best loss: -0.6720754716981132]Step 1000 validation: roc_auc_score=0.64248\n",
            "Step 2000 validation: roc_auc_score=0.657251\n",
            " 40%|████      | 2/5 [05:10<07:46, 155.35s/trial, best loss: -0.6720754716981132]Step 1000 validation: roc_auc_score=0.627655\n",
            "Step 2000 validation: roc_auc_score=0.598437\n",
            " 60%|██████    | 3/5 [07:43<05:09, 154.52s/trial, best loss: -0.6720754716981132]Step 1000 validation: roc_auc_score=0.712722\n",
            "Step 2000 validation: roc_auc_score=0.698275\n",
            " 80%|████████  | 4/5 [10:19<02:35, 155.12s/trial, best loss: -0.6720754716981132]Step 1000 validation: roc_auc_score=0.655418\n",
            "Step 2000 validation: roc_auc_score=0.671321\n",
            "100%|██████████| 5/5 [12:54<00:00, 154.81s/trial, best loss: -0.6720754716981132]\n",
            "Training the best estimator with the best hyperparameters\n",
            "\n",
            "Training the Neural Network for Sweet\n",
            "  0%|          | 0/5 [00:00<?, ?trial/s, best loss=?]Step 1000 validation: roc_auc_score=0.767388\n",
            "Step 2000 validation: roc_auc_score=0.782192\n",
            " 20%|██        | 1/5 [02:35<10:23, 155.87s/trial, best loss: -0.7895840584754612]Step 1000 validation: roc_auc_score=0.742453\n",
            "Step 2000 validation: roc_auc_score=0.805963\n",
            " 40%|████      | 2/5 [05:10<07:44, 154.94s/trial, best loss: -0.8067177166724677]Step 1000 validation: roc_auc_score=0.764138\n",
            "Step 2000 validation: roc_auc_score=0.809673\n",
            " 60%|██████    | 3/5 [07:46<05:10, 155.48s/trial, best loss: -0.8067177166724677]Step 1000 validation: roc_auc_score=0.759729\n",
            "Step 2000 validation: roc_auc_score=0.81287\n",
            " 80%|████████  | 4/5 [10:20<02:35, 155.12s/trial, best loss: -0.8150707324349858]Step 1000 validation: roc_auc_score=0.735211\n",
            "Step 2000 validation: roc_auc_score=0.778139\n",
            "100%|██████████| 5/5 [12:56<00:00, 155.23s/trial, best loss: -0.8150707324349858]\n",
            "Training the best estimator with the best hyperparameters\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metrics_val_df_bal = pd.DataFrame.from_dict(metrics_valid_balanced, orient='index')\n",
        "\n",
        "print(metrics_val_df_bal)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUdGL1_8ccX7",
        "outputId": "17a98b22-6d1b-4b61-d404-b2ca9b4b7faa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   Recall  Specificity  ROC Score\n",
            "CGNN Bitter      0.830330     0.453195   0.753726\n",
            "     Floral      0.622642     0.583981   0.613002\n",
            "     Fruity      0.703297     0.608173   0.692361\n",
            "     Off_flavor  0.648148     0.618677   0.655887\n",
            "     Nutty       0.500000     0.708619   0.622071\n",
            "     Sour        0.357143     0.789434   0.670512\n",
            "     Sweet       0.573626     0.837104   0.786867\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metrics_test_df_bal = pd.DataFrame.from_dict(metrics_test_balanced, orient='index')\n",
        "\n",
        "print(metrics_test_df_bal)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5NY25vJchnj",
        "outputId": "de18ee2c-c788-4f69-d788-54ea01c17364"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   Recall  Specificity  ROC Score\n",
            "CGNN Bitter      0.231920     0.931489   0.533864\n",
            "     Floral      0.736283     0.593469   0.728220\n",
            "     Fruity      1.000000     0.049858   0.659562\n",
            "     Off_flavor  0.998529     0.046046   0.682708\n",
            "     Nutty       0.993243     0.038203   0.629486\n",
            "     Sour        0.962025     0.036168   0.563654\n",
            "     Sweet       0.387500     0.938799   0.756332\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metrics_val_df_bal.to_excel('Validation_metrics_balanced.xlsx')\n",
        "metrics_test_df_bal.to_excel('Test_metrics_balanced.xlsx')"
      ],
      "metadata": {
        "id": "jg7XHptaU66G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}